[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CoMPaSS",
    "section": "",
    "text": "CoMPaSS is A Computational Pipeline for Cross-Platform Concordance Assessment and Navigating Study Design in Microbiome Research\nMicrobiome research has become an integral component of modern biomedical science, offering insights that uniquely complement other omics. To characterize microbial dysbiosis and its impact on human health, researchers have widely employed next-generation sequencing (NGS) technologies, including 16S rRNA gene sequencing and shotgun metagenomic sequencing. However, these approaches are susceptible to technological artifacts that may introduce method-specific bias into analyses and undermine the replicability of discoveries. Researchers often struggle to select appropriate sequencing methods during the study design stage, as they strive to optimize the budget, taxonomic resolution, and analytical accuracy. While 16S rRNA sequencing is a cost-effective and reliable method that offers acceptable taxonomic resolution, shotgun metagenomic sequencing provides higher-resolution profiles and functional insights, albeit with increased cost. To address this challenge, we introduce CoMPaSS (Concordance of Microbiome Sequencing Platforms and Study Initiation Strategy), a computational pipeline designed to enable precise and head-to-head comparison of six downstream analytical tools in efficacy and to navigate microbiome study design. CoMPaSS offers a framework for evaluating cross-platform concordance in statistical inference across multiple contexts, from community diversity indices to taxonomic profiling, and offers integrated tools for power analysis, sample size estimation, and cost assessment to support comprehensive study planning. Based on an extensive simulation study of in-silico microbiota and three real-world microbiome studies in population-based cohorts (i.e., ORIGIN, IBD, TEDDY), CoMPaSS reveals desirable concordance between platforms at higher taxonomic levels, but significant discrepancies at finer taxonomic resolutions and among rare taxa—highlighting the importance of sequencing platform selection in determining study outcomes."
  },
  {
    "objectID": "part_2_eda.html",
    "href": "part_2_eda.html",
    "title": "Part I",
    "section": "",
    "text": "Page with R code\n\n\n\nThis page contains an example template for a lab session, where R code and results are displayed here.\nYou can find more information on how to include code in Quarto website here.\nYou can experiment with code-fold and code-tools in the yaml header above to change how the code cells look like."
  },
  {
    "objectID": "part_2_eda.html#a-cancer-modeling-example",
    "href": "part_2_eda.html#a-cancer-modeling-example",
    "title": "Part I",
    "section": "A Cancer Modeling Example",
    "text": "A Cancer Modeling Example\nExercise on analysis of miRNA, mRNA and protein data from the paper Aure et al, Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer, Genome Medicine, 2015.\nPlease run the code provided to replicate some of the analyses. Make sure you can explain what all the analysis steps do and that you understand all the results.\nIn addition, there are some extra tasks (Task 1), where no R code is provided. Please do these tasks when you have time available at the end of the lab.\n\nLoad the data\nRead the data, and convert to matrix format.\n\nmrna &lt;- read.table(\"data/data_example.txt\", header=T, sep=\"\\t\", dec=\".\")\n\n# Convert to matrix format\n\nmrna &lt;- as.matrix(mrna)\n\nPrint the data\n\nmrna[1:4, 1:4]\n\n      OSL2R.3002T4 OSL2R.3005T1 OSL2R.3013T1 OSL2R.3030T2\nACACA      1.60034     -0.49087     -0.26553     -0.27857\nANXA1     -2.42501     -0.05416     -0.46478     -2.18393\nAR         0.39615     -0.43348     -0.10232      0.58299\nBAK1       0.78627      0.39897      0.22598     -1.31202\n\n\nVisualise the overall distribution of expression levels by histogram\n\nhist(mrna, nclass=40, xlim=c(-5,5), col=\"lightblue\")\n\n\n\n\n\n\n\n\n\n\nTask 1\n\n\n\nThis is a callout-note, and it can be quite useful for exercises. You can find more about callout here.\nExample: Extend the above analysis to cover all genes."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Paper code go-through",
    "section": "",
    "text": "About page\n\n\n\nThis page provide all the codes we used in the paper for downstream analysis and figure generation.\n\n\nFor example: A central problem in machine learning is how to make an algorithm perform well not just on the training data, but also on new inputs. Many strategies in machine learning are explicitly designed to reduce this test error, possibly at the expense of increased training error. These strategies are collectively known as regularisation and they are instrumental for good performance of any kind of prediction or classification model, especially in the context of small data (many features, few samples).\nIn the hands-on tutorial we will use R to perform an integrated analysis of multi-omics data with penalised regression.\n\nContact\nInstructor A: contact\nInstructor B: contact\nInstructor C: contact"
  },
  {
    "objectID": "part_1_prep.html",
    "href": "part_1_prep.html",
    "title": "Preparation",
    "section": "",
    "text": "Page without code\n\n\n\nThis page contains an example for some structured preparation information for a workshop. No code is executed here.\nHere are some preparation information for the participants."
  },
  {
    "objectID": "part_1_prep.html#software",
    "href": "part_1_prep.html#software",
    "title": "Preparation",
    "section": "Software",
    "text": "Software\nIn this workshop we will be using R. You can either\n\nhave R and Rstudio installed on your laptop\nor, use Posit cloud (formerly Rstudio Cloud).\n\nPosit cloud is free of charge for personal users, yet you need to sign up for a new user account and have internet connection.\nThe R package we are using is glmnet."
  },
  {
    "objectID": "part_1_prep.html#data",
    "href": "part_1_prep.html#data",
    "title": "Preparation",
    "section": "Data",
    "text": "Data\nThe datasets we use can be found here (insert link)."
  },
  {
    "objectID": "part_1_prep.html#code",
    "href": "part_1_prep.html#code",
    "title": "Preparation",
    "section": "Code",
    "text": "Code\nThe R scripts used in part 1 and part 2 can be found here (insert link)."
  },
  {
    "objectID": "part_1_prep.html#resources",
    "href": "part_1_prep.html#resources",
    "title": "Preparation",
    "section": "Resources",
    "text": "Resources\nLecture notes (insert link)\nLab notes (insert link)"
  },
  {
    "objectID": "paper_code/about.html",
    "href": "paper_code/about.html",
    "title": "R code for CoMPaSS",
    "section": "",
    "text": "All the R code including simulation parts and real data analysis have been post in the webpage, please go to sidebar to review."
  },
  {
    "objectID": "paper_code/index.html",
    "href": "paper_code/index.html",
    "title": "Title of Your Workshop Session",
    "section": "",
    "text": "Date: Date and time\nRoom: Location\nInstructors: Instructor A, B, C\n\n\n\n\n\n\n\nThis workshop template\n\n\n\nThis workshop template contains 4 pages:\n\nHome: index.qmd (this page)\nAbout: about.qmd\n\nTwo content pages\n\nPage without code: part_1_prep.qmd\nPage with R code: part_2_eda.qmd\n\nIt is straightforward to add more content pages: you need to create a new .qmd file (or copy/paste the existing ones), then link the new page inside _quarto.yml.\n\n\n\n\n\n\n\n\nHomepage of your workshop\n\n\n\nThis is the homepage index.qmd for your workshop, so ideally it should contain some key information such as time and place, instructors and information of the course/workshop.\nIt should be easy to navigate.\n\n\n\nWelcome!\n\nThe goal of the workshop is to … (insert your message)\nFor example, introduce kep concepts in machine learning, such as regularisation.\nWorkshop material can be found in the workshop github repository.\n\n\nLearning Objectives\nAt the end of the tutorial, participants will be able to\n\nunderstand key concepts for … (insert your message)\nFor example, training machine learning models such as regularisation.\nanother objective\n\n\n\nPre-requisites\n\nBasic familiarity with R\nSome other knowledge\n\n\n\n\nSchedule\n\n\n\n\n\n\nTabular schedule\n\n\n\nIt can be useful to include a tabular schedule with links.\n\n\n\n\n\nTime\nTopic\nPresenter\n\n\n\n\n9:00 - 10:30\nSession 1: Preparation\nInstructor A\n\n\n10:45 - 12:00\nSession 2: Exploratory Analysis\nInstructor B, C"
  },
  {
    "objectID": "paper_code/simulation.html",
    "href": "paper_code/simulation.html",
    "title": "R code for simulation results",
    "section": "",
    "text": "Generate simulation\n\n\n####################################################################################################################################\n################################################## Data Simulation #################################################################\n##################################### User Specified Differentiate Genus Features ##################################################\n####################################################################################################################################\nsource(\"SimulateMSeq_V2.R\")\n\nload(\"common_genus.Rdata\")\n\n\nN = 206 #sample size\ninput.conf &lt;- rnorm(N)\ninput.err &lt;- rnorm(N)\ninput.diff.otu.pct = NULL\ninput.diff.otu.mode = \"user_specified\"\nuser_specified_otu = common_genus[1:10]\ninput.covariate.eff.mean = 0.3\n\nnSim = 200\n\n## WGS simulation\nsim_WGS_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_WGS_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para2, nSam = N, nOTU = nrow(physeq.wgs.genus@otu_table),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}\n\nsave(sim_WGS_Genus,file = \"SimulationResults/sim_WGS_Genus.Rdata\")\n\n## 16S simulation\nsim_16S_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_16S_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para1, nSam = N, nOTU = nrow(physeq.16s.genus@otu_table),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}\n\n\n\n\n\n\n\nThis workshop template\n\n\n\nThis workshop template contains 4 pages:\n\nHome: index.qmd (this page)\nAbout: about.qmd\n\nTwo content pages\n\nPage without code: part_1_prep.qmd\nPage with R code: part_2_eda.qmd\n\nIt is straightforward to add more content pages: you need to create a new .qmd file (or copy/paste the existing ones), then link the new page inside _quarto.yml.\n\n\n\n\n\n\n\n\nHomepage of your workshop\n\n\n\nThis is the homepage index.qmd for your workshop, so ideally it should contain some key information such as time and place, instructors and information of the course/workshop.\nIt should be easy to navigate.\n\n\n\nWelcome!\n\nThe goal of the workshop is to … (insert your message)\nFor example, introduce kep concepts in machine learning, such as regularisation.\nWorkshop material can be found in the workshop github repository.\n\n\nLearning Objectives\nAt the end of the tutorial, participants will be able to\n\nunderstand key concepts for … (insert your message)\nFor example, training machine learning models such as regularisation.\nanother objective\n\n\n\nPre-requisites\n\nBasic familiarity with R\nSome other knowledge\n\n\n\n\nSchedule\n\n\n\n\n\n\nTabular schedule\n\n\n\nIt can be useful to include a tabular schedule with links.\n\n\n\n\n\nTime\nTopic\nPresenter\n\n\n\n\n9:00 - 10:30\nSession 1: Preparation\nInstructor A\n\n\n10:45 - 12:00\nSession 2: Exploratory Analysis\nInstructor B, C"
  },
  {
    "objectID": "paper_code/simulation.html#generate-simulation",
    "href": "paper_code/simulation.html#generate-simulation",
    "title": "R code for simulation results",
    "section": "1. Generate simulation",
    "text": "1. Generate simulation\n\n####################################################################################################################################\n################################################## Data Simulation #################################################################\n##################################### User Specified Differentiate Genus Features ##################################################\n####################################################################################################################################\nsource(\"SimulateMSeq_V2.R\")\n\nload(\"common_genus.Rdata\")\n\n\nN = 206 #sample size\ninput.conf &lt;- rnorm(N)\ninput.err &lt;- rnorm(N)\ninput.diff.otu.pct = NULL\ninput.diff.otu.mode = \"user_specified\"\nuser_specified_otu = common_genus[1:10]\ninput.covariate.eff.mean = 0.3\n\nnSim = 200\n\n## WGS simulation\nsim_WGS_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_WGS_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para2, nSam = N, nOTU = nrow(physeq.wgs.genus@otu_table),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}\n\nsave(sim_WGS_Genus,file = \"SimulationResults/sim_WGS_Genus.Rdata\")\n\n## 16S simulation\nsim_16S_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_16S_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para1, nSam = N, nOTU = nrow(physeq.16s.genus@otu_table),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}"
  },
  {
    "objectID": "paper_code/simulation.html#global-power-checking",
    "href": "paper_code/simulation.html#global-power-checking",
    "title": "R code for simulation results",
    "section": "2. Global power checking",
    "text": "2. Global power checking\n\n###########################################################################\n########################### MiRKAT Integration ############################\n###########################################################################\nlibrary(MiRKAT)\nlibrary(vegan)\n\nload(\"SimulationResults/sim_WGS_Genus.Rdata\")\nload(\"SimulationResults/sim_16S_Genus.Rdata\")\n\nnSim = 200\nresult.list = lapply(c(1:nSim), MiRKAT_Test)\nresults.df = data.frame(do.call(rbind,result.list))\ncolMeans(results.df)\n\n###########################\n###### Visualization ######\n###########################\nlibrary(readxl)\nMiRKAT_Power = read_excel(\"Simulation_V2_Results/MiRKAT Results.xlsx\")\nMiRKAT_Power$Platform = factor(MiRKAT_Power$Platform, levels = c(\"Multiple\", \"WGS\", \"16s\"))\nMiRKAT_Power$Diff_OTU_Order= factor(MiRKAT_Power$Diff_OTU_Order, levels = unique(MiRKAT_Power$Diff_OTU_Order))\n\nplot.MiRKAT = ggplot(MiRKAT_Power, \n                     aes_string(x = \"Diff_OTU_Order\", y = \"BC_MiRKAT_Power\", \n                                color = \"Platform\", group = \"Platform\")) +\n  geom_line() +\n  geom_point() +\n  ylim(0,1) +\n  labs(title = \"MiRKAT\", y = \"Power\",x = \"Differenciate OTU Abundance Order\")+\n  scale_color_manual(values = c(\"WGS\" = \"red\", \"16s\" = \"blue\", \"Multiple\" = \"green\"))\n\n##############################################################################################################################\n########################################### Global Results checking ##########################################################\n############################### User Specified Differentiate Genus Features ##################################################\n##############################################################################################################################\nrm(list = ls())\n\n\nlibrary(vegan)\nlibrary(phyloseq)\nlibrary(microbiome)\n\nsource(\"SimulateMSeq.R\")\n\nload(\"SimulationResults/sim_WGS_Genus.Rdata\")\nload(\"SimulationResults/sim_16S_Genus.Rdata\")\n\nsim.sum = sapply(sim_WGS_Genus, Global_Test)\n\nsim.sum = data.frame(t(sim.sum))\ncolnames(sim.sum) = c(\"Shannon_p\", \"Inv_Simpson_P\")\ncolnames(sim.sum) = c(\"Shannon_p\", \"Inv_Simpson_P\", \"Bray_Curtis_P\")\np_thresh = 0.05\ncolMeans(ifelse(sim.sum &lt; p_thresh,1,0))\n\n##########################\n##### Visualization ######\n##########################\nlibrary(ggplot2)\nlibrary(gridExtra)\n\nresults = read.csv(\"Simulation_V2_Results/Global_Simulation_Results.csv\")\nresults$Differentiated_Feature_Number = factor(results$Differentiated_Feature_Number, levels = unique(results$Differentiated_Feature_Number))\n\nplot1 = ggplot(results, aes(x = Differentiated_Feature_Number, y = Shannon_Power, color = Platform,group = Platform)) +\n  geom_line() +\n  geom_point() +\n  ylim(0,1) +\n  labs(title = \"Shannon Index\", y = \"Power\",x = \"Differenciate OTU Abundance Order\")+\n  scale_color_manual(values = c(\"WGS\" = \"red\", \"SixteenS\" = \"blue\"))\n\nplot2 =  ggplot(results, aes(x = Differentiated_Feature_Number, y = Bray_Power, color = Platform,group = Platform)) +\n  geom_line() +\n  geom_point() +\n  ylim(0,1) +\n  labs(title = \"Bray-Curtis Distance\",y = \"Power\", x = \"Differenciate OTU Abundance Order\")+\n  scale_color_manual(values = c(\"WGS\" = \"red\", \"SixteenS\" = \"blue\"))\n\n\ncombined_plots = plot1 +plot2 +plot.MiRKAT +\n  plot_layout(guides = \"collect\")\nggsave(\"Plots/Global_Power_w_Specified_Genus.png\",combined_plots,width = 18,height = 8)"
  },
  {
    "objectID": "paper_code/simulation.html#univariate-power-analysis",
    "href": "paper_code/simulation.html#univariate-power-analysis",
    "title": "R code for simulation results",
    "section": "3. Univariate power analysis",
    "text": "3. Univariate power analysis\n\n###########################################################################################################################\n########################################### Univaraite ####################################################################\n############################ User Specified Differentiate Genus Features ##################################################\n###########################################################################################################################\nlibrary(DESeq2)\nlibrary(ANCOMBC)\nlibrary(mltools)\n\n\nsim_Rate = lapply(sim_WGS_Genus,TP_Rate)\n\nsim_Rate_df = do.call(rbind,sim_Rate)\n\ncolnames(sim_Rate_df) = c(\"DEseq2_TPR\",\"DEseq2_TNR\",  \"DEseq2_FDR\", \"DEseq2_MCC\",\n                          \"ANCOMBC_TPR\", \"ANCOMBC_TNR\",\"ANCOMBC_FDR\",\"ANCOMBC_MCC\",\n                          \"ANCOMBC2_TPR\", \"ANCOMBC2_TNR\",\"ANCOMBC2_FDR\", \"ANCOMBC2_MCC\",\n                          \"Wilcoxon_TPR\",  \"Wilcoxon_TNR\", \"Wilcoxon_FDR\",\"Wilcoxon_MCC\")"
  },
  {
    "objectID": "paper_code/Real_data.html",
    "href": "paper_code/Real_data.html",
    "title": "R code for real data analysis",
    "section": "",
    "text": "################################################################################################\n############################# Loading your Phyloseq object #####################################\n################################################################################################\n## WGS--------------------------------------------------------\nload(\"WGSphylo_w_tree.Rdata\")\nphylo_wgs = subset_samples(phy, diagnosis %in% c(\"cd\",\"uc\"))\nphylo_wgs = subset_taxa(phylo_wgs, kingdom==\"Bacteria\")\n\n# Filter to keep only taxa where the domain is 'Bacteria'\ntax_table_df &lt;- as.data.frame(tax_table(physeq))\nbacteria_taxa &lt;- tax_table_df[tax_table_df[, \"kingdom\"] == \"Bacteria\", ] ## Only keep Bacteria\nbacteria_ids &lt;- rownames(bacteria_taxa)\nphylo_wgs &lt;- prune_taxa(bacteria_ids, physeq)\n\ntax_table &lt;- as.data.frame(tax_table(phylo_wgs))\ntax_table$phylum &lt;- gsub(\"bacteriota$\",\"bacteria\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"bacterota$\",\"bacteria\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"etes$\",\"ota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"bia$\",\"biota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"chaota$\",\"chaetota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"Deinococcus-Thermus$\",\"Deinococcota\", tax_table$phylum, perl = TRUE)\n\ntax_matrix &lt;- as.matrix(tax_table)\ntax_table(phylo_wgs) &lt;- tax_matrix\n\n# Now bacteria_phyloseq contains only bacterial data\nphyseq.wgs.genus = aggregate_taxa(phylo_wgs,level = \"genus\")\nphyseq.wgs.phylum = aggregate_taxa(phylo_wgs,level = \"phylum\")\n\n## 16s--------------------------------------------------------\nload(\"SixteenSphylo.Rdata\")\nphylo_16s = subset_samples(ps_amp_filter, diagnosis %in% c(\"uc\",\"cd\"))\nphylo_16s = subset_taxa(phylo_16s, Kingdom ==\"Bacteria\")\n\n# Filter to keep only taxa where the domain is 'Bacteria'\ntax_table_df &lt;- as.data.frame(tax_table(physeq))\nbacteria_taxa &lt;- tax_table_df[tax_table_df[, \"Domain\"] == \"Bacteria\", ] ## Only keep Bacteria\nbacteria_ids &lt;- rownames(bacteria_taxa)\nphylo_16s &lt;- prune_taxa(bacteria_ids, physeq)\n\ntax_table &lt;- as.data.frame(tax_table(phylo_16s))\ntax_table$Phylum &lt;- gsub(\"bacteriota$\",\"bacteria\", tax_table$Phylum, perl = TRUE)\ntax_table$Phylum &lt;- gsub(\"bacterota$\",\"bacteria\", tax_table$Phylum, perl = TRUE)\ntax_matrix &lt;- as.matrix(tax_table)\ntax_table(phylo_16s) &lt;- tax_matrix\n\n\nphyseq.16s.genus = aggregate_taxa(phylo_16s,level = \"Genus\")\nphyseq.16s.phylum = aggregate_taxa(phylo_16s,level = \"Phylum\")\n\n\n## Common Features --------------------------------------------------------\nnumbers = lapply(c(1:7),function(level){\n  n1 = length(na.omit(unique(phylo_16s@tax_table[, level])))\n  n2 = length(na.omit(unique(phylo_wgs@tax_table[, level])))\n  n3 = length(intersect(na.omit(unique(phylo_wgs@tax_table[, level])),\n                        na.omit(unique(phylo_16s@tax_table[, level]))))\n  return(c(n1,n2,n3))\n})\n\nnumbers = data.frame(do.call(cbind,numbers))\ncolnames(numbers) =c(\"Domain\" ,\"Phylum\",\"Class\", \"Order\", \"Family\", \"Genus\",\"Species\")\nrownames(numbers) = c(\"16s\",\"wgs\",\"Overlap\")\nnumbers\n\n# Function to plot and save Venn\nplot_venn_save &lt;- function(level, filename) {\n  only_16s &lt;- numbers[\"16s\", level] - numbers[\"Overlap\", level]\n  only_wgs &lt;- numbers[\"wgs\", level] - numbers[\"Overlap\", level]\n  overlap &lt;- numbers[\"Overlap\", level]\n  \n  # Open PDF file\n  pdf(file = filename, width = 5, height = 3)  # You can adjust width/height\n  \n  # Plot Venn\n  VennDiagram::draw.pairwise.venn(\n    area1 = only_16s + overlap,\n    area2 = only_wgs + overlap,\n    cross.area = overlap,\n    category = c(\"\", \"\"),\n    fill = c(\"#ffa551\", \"#70afdf\"),\n    lty = \"blank\",\n    cex = 3,\n    cat.cex = 2,\n    cat.pos = c(-20, 20),\n    cat.dist = 0.05\n  )\n  \n  # Add the label on the left\n  grid.text(level, x = 0.12, y = 0.95, gp = gpar(fontsize = 24, fontface = \"bold\"))\n  \n  \n  # Close and save the PDF\n  dev.off()\n}\n\n# Example: Save the \"Genus\" Venn diagram\nplot_venn_save(\"Genus\", \"Genus_Venn.pdf\")\n###################################################################################################################\n################################# Common Genus Feature Correlations ###############################################\n###################################################################################################################\n## Check if OTU table samples order matches!!!\nall(colnames(physeq.16s.genus@otu_table) == colnames(physeq.wgs.genus@otu_table))\n\n## Transform to Relative Abundance\nphyseq.16s.genus.rel = transform_sample_counts(physeq.16s.genus, function(x) x / sum(x))\nphyseq.wgs.genus.rel = transform_sample_counts(physeq.wgs.genus, function(x) x / sum(x))\n\n## Common genus features from the most to least abundant\ngenus_16s = names(sort(taxa_sums(physeq.16s.genus.rel), TRUE))\ngenus_16s  = genus_16s[!grepl(\"Unknown\", genus_16s)]\n\ngenus_wgs = names(sort(taxa_sums(physeq.wgs.genus.rel), TRUE))\ngenus_wgs = genus_wgs[!grepl(\"Unknown\", genus_wgs)]\n\ncommon_genus = intersect(genus_16s,genus_wgs)\ncommon_genus_df =  data.frame(common = common_genus, \n                              SixS_Rank = match(common_genus, genus_16s),\n                              WGS_Rank = match(common_genus, genus_wgs))\n#write.csv(common_genus_df,file = \"Full_common_genus.csv\",row.names = FALSE)\n\n\n## Pearson Correlation ---------------------------------------------------------------------------\ncommon_genus_cor = lapply(common_genus, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,])\n  cor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Distance Correlation ---------------------------------------------------------------------------\nlibrary(energy)\ncommon_genus_cor = lapply(common_genus, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,])\n  dcor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Correlation Plot ------------------------------------------------------------------------------\ncommon_genus_cor = do.call(rbind,common_genus_cor)\ncommon_genus_cor_df = data.frame(Genus = common_genus,Corr = common_genus_cor)\n\nlibrary(viridis)\ncolor_palette = viridis_pal()(length(unique(common_genus_cor_df$Genus)))\ncommon_genus_cor_df$Genus = factor(common_genus_cor_df$Genus, levels = common_genus_cor_df$Genus)\n\ncorr_plot = ggplot(data=common_genus_cor_df, aes(x=Genus, y=Corr,fill = Genus)) +\n  geom_bar(stat=\"identity\")+\n  scale_fill_manual(values = color_palette) +  \n  labs(x = NULL, y = \"Correlation\",title = \"Common Genera\")  +\n  theme(legend.position = \"right\",axis.title.x = element_blank(),  \n        axis.text.x = element_blank()) \n\n#ggsave(\"Real_Plots/genus_dcorr_plot.pdf\",corr_plot,height = 5,width = 20)\n\n\n## Feature-wise scatter plot ---------------------------------------------------------------------\nMost_Abun_Genus = as.character(common_genus_cor_df[1:50,\"Genus\"])\n\nMost_Abun_Genus_Plots = lapply(Most_Abun_Genus, function(feature){\n  feature_df = data.frame(rel_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,]),\n                          rel_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,]))\n  limit = max(feature_df)\n  cor_value = round(common_genus_cor_df[which(common_genus_cor_df$Genus == feature),\"Corr\"],2)\n  ggplot(feature_df, aes(x=rel_16s, y=rel_wgs))  + \n    geom_point() +\n    geom_smooth(method=lm) +\n    theme_classic()+\n    labs(title = paste0(feature))+\n    ylim(0, limit)+\n    xlim(0, limit)+\n    annotate(\"text\",x = 0, y = limit,label = paste0(\"r=\", cor_value),hjust = -0.1, vjust = 1.1,size = 5)\n})\n\nlibrary(patchwork)\nCombined_Plots &lt;- wrap_plots(Most_Abun_Genus_Plots, ncol = 10)\n\n#ggsave(\"Real_Plots/Most_Abun_Genus_Plots.pdf\",Combined_Plots,height = 10,width = 20)\n\n\n\n###################################################################################################################\n################################# Common Phylum Feature Correlations ###############################################\n###################################################################################################################\n## Check if OTU table samples order matches!!!\nall(colnames(physeq.16s.phylum@otu_table) == colnames(physeq.wgs.phylum@otu_table))\n\n## Transform to Relative Abundance\nphyseq.16s.phylum.rel = transform_sample_counts(physeq.16s.phylum, function(x) x / sum(x))\nphyseq.wgs.phylum.rel = transform_sample_counts(physeq.wgs.phylum, function(x) x / sum(x))\n\n## Common genus features from the most to least abundant\nphylum_16s = names(sort(taxa_sums(physeq.16s.phylum.rel), TRUE))\nphylum_16s  = phylum_16s [!grepl(\"Unknown\", phylum_16s)]\n\nphylum_wgs = names(sort(taxa_sums(physeq.wgs.phylum.rel), TRUE))\nphylum_wgs = phylum_wgs[!grepl(\"Unknown\", phylum_wgs)]\n\ncommon_phylum = intersect(phylum_16s,phylum_wgs)\n#save(common_phylum ,file = \"Full_common_phylum.Rdata\")\n\n## Pearson Correlation ---------------------------------------------------------------------------\ncommon_phylum_cor = lapply(common_phylum, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,])\n  cor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Distance Correlation ---------------------------------------------------------------------------\nlibrary(energy)\ncommon_phylum_cor = lapply(common_phylum, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,])\n  dcor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Correlation Plot ------------------------------------------------------------------------------\ncommon_phylum_cor = do.call(rbind,common_phylum_cor)\ncommon_phylum_cor_df = data.frame(Phylum = common_phylum,Corr = common_phylum_cor)\n\nlibrary(viridis)\ncolor_palette = viridis_pal()(length(unique(common_phylum_cor_df$Phylum)))\ncommon_phylum_cor_df$Phylum = factor(common_phylum_cor_df$Phylum, levels = common_phylum_cor_df$Phylum)\n\ncorr_plot = ggplot(data=common_phylum_cor_df, aes(x=Phylum, y=Corr,fill = Phylum)) +\n  geom_bar(stat=\"identity\")+\n  scale_fill_manual(values = color_palette) +  \n  labs(x = NULL, y = NULL)  +\n  ylim(-0.05,1)+\n  theme_minimal()+\n  theme(legend.position = \"right\",\n        legend.text = element_text(size = 8),\n        legend.key.size = unit(0.3, \"cm\"),\n        axis.title.x = element_blank(),  \n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        axis.line = element_line(color = \"black\")) \n\nggsave(\"Real_Plots/phylum_corr_plot.pdf\",corr_plot,height = 2,width = 4)\n\n\n\n\n## Plot of Most Abundant Features\nMost_Abun_Phylum = as.character(common_phylum_cor_df[,\"Phylum\"])\n\nMost_Abun_Phylum_Plots = lapply(Most_Abun_Phylum, function(feature){\n  feature_df = data.frame(rel_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,]),\n                          rel_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,]))\n  limit = max(feature_df)\n  cor_value = round(common_phylum_cor_df[which(common_phylum_cor_df$Phylum == feature),\"Corr\"],2)\n  ggplot(feature_df, aes(x=rel_16s, y=rel_wgs))  + \n    geom_point() +\n    geom_smooth(method=lm) +\n    theme_classic()+\n    labs(title = feature)+\n    ylim(0, limit)+\n    xlim(0, limit)+\n    annotate(\"text\",x = 0, y = limit,label = paste0(\"rho = \", cor_value),hjust = -0.1, vjust = 1.1,size = 5)\n})\n\nlibrary(patchwork)\nCombined_Plots &lt;- wrap_plots(Most_Abun_Phylum_Plots, ncol = 6)"
  },
  {
    "objectID": "paper_code/Real_data.html#loading-datasets-and-correlation-analysis",
    "href": "paper_code/Real_data.html#loading-datasets-and-correlation-analysis",
    "title": "R code for real data analysis",
    "section": "",
    "text": "################################################################################################\n############################# Loading your Phyloseq object #####################################\n################################################################################################\n## WGS--------------------------------------------------------\nload(\"WGSphylo_w_tree.Rdata\")\nphylo_wgs = subset_samples(phy, diagnosis %in% c(\"cd\",\"uc\"))\nphylo_wgs = subset_taxa(phylo_wgs, kingdom==\"Bacteria\")\n\n# Filter to keep only taxa where the domain is 'Bacteria'\ntax_table_df &lt;- as.data.frame(tax_table(physeq))\nbacteria_taxa &lt;- tax_table_df[tax_table_df[, \"kingdom\"] == \"Bacteria\", ] ## Only keep Bacteria\nbacteria_ids &lt;- rownames(bacteria_taxa)\nphylo_wgs &lt;- prune_taxa(bacteria_ids, physeq)\n\ntax_table &lt;- as.data.frame(tax_table(phylo_wgs))\ntax_table$phylum &lt;- gsub(\"bacteriota$\",\"bacteria\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"bacterota$\",\"bacteria\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"etes$\",\"ota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"bia$\",\"biota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"chaota$\",\"chaetota\", tax_table$phylum, perl = TRUE)\ntax_table$phylum &lt;- gsub(\"Deinococcus-Thermus$\",\"Deinococcota\", tax_table$phylum, perl = TRUE)\n\ntax_matrix &lt;- as.matrix(tax_table)\ntax_table(phylo_wgs) &lt;- tax_matrix\n\n# Now bacteria_phyloseq contains only bacterial data\nphyseq.wgs.genus = aggregate_taxa(phylo_wgs,level = \"genus\")\nphyseq.wgs.phylum = aggregate_taxa(phylo_wgs,level = \"phylum\")\n\n## 16s--------------------------------------------------------\nload(\"SixteenSphylo.Rdata\")\nphylo_16s = subset_samples(ps_amp_filter, diagnosis %in% c(\"uc\",\"cd\"))\nphylo_16s = subset_taxa(phylo_16s, Kingdom ==\"Bacteria\")\n\n# Filter to keep only taxa where the domain is 'Bacteria'\ntax_table_df &lt;- as.data.frame(tax_table(physeq))\nbacteria_taxa &lt;- tax_table_df[tax_table_df[, \"Domain\"] == \"Bacteria\", ] ## Only keep Bacteria\nbacteria_ids &lt;- rownames(bacteria_taxa)\nphylo_16s &lt;- prune_taxa(bacteria_ids, physeq)\n\ntax_table &lt;- as.data.frame(tax_table(phylo_16s))\ntax_table$Phylum &lt;- gsub(\"bacteriota$\",\"bacteria\", tax_table$Phylum, perl = TRUE)\ntax_table$Phylum &lt;- gsub(\"bacterota$\",\"bacteria\", tax_table$Phylum, perl = TRUE)\ntax_matrix &lt;- as.matrix(tax_table)\ntax_table(phylo_16s) &lt;- tax_matrix\n\n\nphyseq.16s.genus = aggregate_taxa(phylo_16s,level = \"Genus\")\nphyseq.16s.phylum = aggregate_taxa(phylo_16s,level = \"Phylum\")\n\n\n## Common Features --------------------------------------------------------\nnumbers = lapply(c(1:7),function(level){\n  n1 = length(na.omit(unique(phylo_16s@tax_table[, level])))\n  n2 = length(na.omit(unique(phylo_wgs@tax_table[, level])))\n  n3 = length(intersect(na.omit(unique(phylo_wgs@tax_table[, level])),\n                        na.omit(unique(phylo_16s@tax_table[, level]))))\n  return(c(n1,n2,n3))\n})\n\nnumbers = data.frame(do.call(cbind,numbers))\ncolnames(numbers) =c(\"Domain\" ,\"Phylum\",\"Class\", \"Order\", \"Family\", \"Genus\",\"Species\")\nrownames(numbers) = c(\"16s\",\"wgs\",\"Overlap\")\nnumbers\n\n# Function to plot and save Venn\nplot_venn_save &lt;- function(level, filename) {\n  only_16s &lt;- numbers[\"16s\", level] - numbers[\"Overlap\", level]\n  only_wgs &lt;- numbers[\"wgs\", level] - numbers[\"Overlap\", level]\n  overlap &lt;- numbers[\"Overlap\", level]\n  \n  # Open PDF file\n  pdf(file = filename, width = 5, height = 3)  # You can adjust width/height\n  \n  # Plot Venn\n  VennDiagram::draw.pairwise.venn(\n    area1 = only_16s + overlap,\n    area2 = only_wgs + overlap,\n    cross.area = overlap,\n    category = c(\"\", \"\"),\n    fill = c(\"#ffa551\", \"#70afdf\"),\n    lty = \"blank\",\n    cex = 3,\n    cat.cex = 2,\n    cat.pos = c(-20, 20),\n    cat.dist = 0.05\n  )\n  \n  # Add the label on the left\n  grid.text(level, x = 0.12, y = 0.95, gp = gpar(fontsize = 24, fontface = \"bold\"))\n  \n  \n  # Close and save the PDF\n  dev.off()\n}\n\n# Example: Save the \"Genus\" Venn diagram\nplot_venn_save(\"Genus\", \"Genus_Venn.pdf\")\n###################################################################################################################\n################################# Common Genus Feature Correlations ###############################################\n###################################################################################################################\n## Check if OTU table samples order matches!!!\nall(colnames(physeq.16s.genus@otu_table) == colnames(physeq.wgs.genus@otu_table))\n\n## Transform to Relative Abundance\nphyseq.16s.genus.rel = transform_sample_counts(physeq.16s.genus, function(x) x / sum(x))\nphyseq.wgs.genus.rel = transform_sample_counts(physeq.wgs.genus, function(x) x / sum(x))\n\n## Common genus features from the most to least abundant\ngenus_16s = names(sort(taxa_sums(physeq.16s.genus.rel), TRUE))\ngenus_16s  = genus_16s[!grepl(\"Unknown\", genus_16s)]\n\ngenus_wgs = names(sort(taxa_sums(physeq.wgs.genus.rel), TRUE))\ngenus_wgs = genus_wgs[!grepl(\"Unknown\", genus_wgs)]\n\ncommon_genus = intersect(genus_16s,genus_wgs)\ncommon_genus_df =  data.frame(common = common_genus, \n                              SixS_Rank = match(common_genus, genus_16s),\n                              WGS_Rank = match(common_genus, genus_wgs))\n#write.csv(common_genus_df,file = \"Full_common_genus.csv\",row.names = FALSE)\n\n\n## Pearson Correlation ---------------------------------------------------------------------------\ncommon_genus_cor = lapply(common_genus, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,])\n  cor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Distance Correlation ---------------------------------------------------------------------------\nlibrary(energy)\ncommon_genus_cor = lapply(common_genus, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,])\n  dcor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Correlation Plot ------------------------------------------------------------------------------\ncommon_genus_cor = do.call(rbind,common_genus_cor)\ncommon_genus_cor_df = data.frame(Genus = common_genus,Corr = common_genus_cor)\n\nlibrary(viridis)\ncolor_palette = viridis_pal()(length(unique(common_genus_cor_df$Genus)))\ncommon_genus_cor_df$Genus = factor(common_genus_cor_df$Genus, levels = common_genus_cor_df$Genus)\n\ncorr_plot = ggplot(data=common_genus_cor_df, aes(x=Genus, y=Corr,fill = Genus)) +\n  geom_bar(stat=\"identity\")+\n  scale_fill_manual(values = color_palette) +  \n  labs(x = NULL, y = \"Correlation\",title = \"Common Genera\")  +\n  theme(legend.position = \"right\",axis.title.x = element_blank(),  \n        axis.text.x = element_blank()) \n\n#ggsave(\"Real_Plots/genus_dcorr_plot.pdf\",corr_plot,height = 5,width = 20)\n\n\n## Feature-wise scatter plot ---------------------------------------------------------------------\nMost_Abun_Genus = as.character(common_genus_cor_df[1:50,\"Genus\"])\n\nMost_Abun_Genus_Plots = lapply(Most_Abun_Genus, function(feature){\n  feature_df = data.frame(rel_16s = as.vector(physeq.16s.genus.rel@otu_table[feature,]),\n                          rel_wgs = as.vector(physeq.wgs.genus.rel@otu_table[feature,]))\n  limit = max(feature_df)\n  cor_value = round(common_genus_cor_df[which(common_genus_cor_df$Genus == feature),\"Corr\"],2)\n  ggplot(feature_df, aes(x=rel_16s, y=rel_wgs))  + \n    geom_point() +\n    geom_smooth(method=lm) +\n    theme_classic()+\n    labs(title = paste0(feature))+\n    ylim(0, limit)+\n    xlim(0, limit)+\n    annotate(\"text\",x = 0, y = limit,label = paste0(\"r=\", cor_value),hjust = -0.1, vjust = 1.1,size = 5)\n})\n\nlibrary(patchwork)\nCombined_Plots &lt;- wrap_plots(Most_Abun_Genus_Plots, ncol = 10)\n\n#ggsave(\"Real_Plots/Most_Abun_Genus_Plots.pdf\",Combined_Plots,height = 10,width = 20)\n\n\n\n###################################################################################################################\n################################# Common Phylum Feature Correlations ###############################################\n###################################################################################################################\n## Check if OTU table samples order matches!!!\nall(colnames(physeq.16s.phylum@otu_table) == colnames(physeq.wgs.phylum@otu_table))\n\n## Transform to Relative Abundance\nphyseq.16s.phylum.rel = transform_sample_counts(physeq.16s.phylum, function(x) x / sum(x))\nphyseq.wgs.phylum.rel = transform_sample_counts(physeq.wgs.phylum, function(x) x / sum(x))\n\n## Common genus features from the most to least abundant\nphylum_16s = names(sort(taxa_sums(physeq.16s.phylum.rel), TRUE))\nphylum_16s  = phylum_16s [!grepl(\"Unknown\", phylum_16s)]\n\nphylum_wgs = names(sort(taxa_sums(physeq.wgs.phylum.rel), TRUE))\nphylum_wgs = phylum_wgs[!grepl(\"Unknown\", phylum_wgs)]\n\ncommon_phylum = intersect(phylum_16s,phylum_wgs)\n#save(common_phylum ,file = \"Full_common_phylum.Rdata\")\n\n## Pearson Correlation ---------------------------------------------------------------------------\ncommon_phylum_cor = lapply(common_phylum, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,])\n  cor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Distance Correlation ---------------------------------------------------------------------------\nlibrary(energy)\ncommon_phylum_cor = lapply(common_phylum, function(feature){\n  rel_abun_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,])\n  rel_abun_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,])\n  dcor(rel_abun_16s, rel_abun_wgs)\n})\n\n## Correlation Plot ------------------------------------------------------------------------------\ncommon_phylum_cor = do.call(rbind,common_phylum_cor)\ncommon_phylum_cor_df = data.frame(Phylum = common_phylum,Corr = common_phylum_cor)\n\nlibrary(viridis)\ncolor_palette = viridis_pal()(length(unique(common_phylum_cor_df$Phylum)))\ncommon_phylum_cor_df$Phylum = factor(common_phylum_cor_df$Phylum, levels = common_phylum_cor_df$Phylum)\n\ncorr_plot = ggplot(data=common_phylum_cor_df, aes(x=Phylum, y=Corr,fill = Phylum)) +\n  geom_bar(stat=\"identity\")+\n  scale_fill_manual(values = color_palette) +  \n  labs(x = NULL, y = NULL)  +\n  ylim(-0.05,1)+\n  theme_minimal()+\n  theme(legend.position = \"right\",\n        legend.text = element_text(size = 8),\n        legend.key.size = unit(0.3, \"cm\"),\n        axis.title.x = element_blank(),  \n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        axis.line = element_line(color = \"black\")) \n\nggsave(\"Real_Plots/phylum_corr_plot.pdf\",corr_plot,height = 2,width = 4)\n\n\n\n\n## Plot of Most Abundant Features\nMost_Abun_Phylum = as.character(common_phylum_cor_df[,\"Phylum\"])\n\nMost_Abun_Phylum_Plots = lapply(Most_Abun_Phylum, function(feature){\n  feature_df = data.frame(rel_16s = as.vector(physeq.16s.phylum.rel@otu_table[feature,]),\n                          rel_wgs = as.vector(physeq.wgs.phylum.rel@otu_table[feature,]))\n  limit = max(feature_df)\n  cor_value = round(common_phylum_cor_df[which(common_phylum_cor_df$Phylum == feature),\"Corr\"],2)\n  ggplot(feature_df, aes(x=rel_16s, y=rel_wgs))  + \n    geom_point() +\n    geom_smooth(method=lm) +\n    theme_classic()+\n    labs(title = feature)+\n    ylim(0, limit)+\n    xlim(0, limit)+\n    annotate(\"text\",x = 0, y = limit,label = paste0(\"rho = \", cor_value),hjust = -0.1, vjust = 1.1,size = 5)\n})\n\nlibrary(patchwork)\nCombined_Plots &lt;- wrap_plots(Most_Abun_Phylum_Plots, ncol = 6)"
  },
  {
    "objectID": "paper_code/Real_data.html#diversity-plot",
    "href": "paper_code/Real_data.html#diversity-plot",
    "title": "R code for real data analysis",
    "section": "2. Diversity plot",
    "text": "2. Diversity plot\n\n## Alpha Diversity ----------------------------------------------------------------------------\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\nlibrary(vegan)\n\n# Rafefaction\nx = as.data.frame(t(otu_table(phylo_16s)))\npdf(\"Real_Plots/RF_16S.pdf\", width = 4, height = 3) # Width and height are in inches for PDFs\nrare_curve &lt;- rarecurve(x, step = 2000, sample = 3000, col = \"blue\", cex = 0.6,label = FALSE,xlab =\"\")\ndev.off()\n\nx = as.data.frame(t(otu_table(phylo_wgs)))\npdf(\"Real_Plots/RF_WGS.pdf\", width = 4, height = 3) # Width and height are in inches for PDFs\nrare_curve &lt;- rarecurve(x, step = 2000, sample = 40000, col = \"blue\", cex = 0.6,label = FALSE,xlab =\"\")\ndev.off()\n\n# Function to calculate alpha diversity and reshape data\nget_alpha_data &lt;- function(physeq, sample_size, sequencing_type) {\n  # Rarefy and get metadata\n  physeq_rarefied &lt;- rarefy_even_depth(physeq, sample.size = sample_size, rngseed = 2024)\n  meta &lt;- meta(physeq_rarefied)\n  \n  # Calculate alpha diversity indices\n  Alp_ind &lt;- alpha(physeq_rarefied, index = c(\"shannon\", \"inverse_simpson\", \"observed\"))\n  colnames(Alp_ind) &lt;- c(\"observed\", \"shannon\", \"inverse_simpson\")\n  Alp_ind$diagnosis &lt;- factor(meta$diagnosis)\n  Alp_ind$sequencing &lt;- sequencing_type\n  \n  # Convert to long format\n  Alp_long &lt;- Alp_ind %&gt;%\n    pivot_longer(cols = c(\"observed\", \"shannon\", \"inverse_simpson\"), \n                 names_to = \"Index\", values_to = \"Diversity\")\n  \n  return(Alp_long)\n}\n\n# Get alpha diversity data for 16S\nalpha_16s &lt;- get_alpha_data(phylo_16s, sample_size = 5000, sequencing_type = \"16S\")\n# Get alpha diversity data for WGS\nalpha_wgs &lt;- get_alpha_data(phylo_wgs, sample_size = 30000, sequencing_type = \"WGS\")\n\n# Combine both datasets\nalpha_combined &lt;- bind_rows(alpha_16s, alpha_wgs)\n\n# Function to perform Wilcoxon test and add p-values\nget_p_value &lt;- function(data) {\n  test &lt;- wilcox.test(Diversity ~ diagnosis, data = data, alternative = \"two.sided\")\n  return(round(test$p.value, 4))\n}\n\n# Add p-values to the data frame\np_values &lt;- alpha_combined %&gt;%\n  group_by(sequencing, Index) %&gt;%\n  summarise(p_value = get_p_value(cur_data()))\n\n# Merge p-values into the combined data\nalpha_combined &lt;- left_join(alpha_combined, p_values, by = c(\"sequencing\", \"Index\"))\ny = \n\ncorrelation_plot &lt;- function(x, y) {\n  model &lt;- lm(y ~ x)\n  sortx &lt;- sort(x)\n  pred &lt;- predict(model, newdata = data.frame(x = x_sorted), interval = \"confidence\")\n  \n  # Diversity Correlation heatscatter\n  heatscatter(x, y,\n              xlab = \"X\",                      # X label\n              ylab = \"Y\",                      # Y label\n              main = \"Correlation Plot\",       # Main title\n              color.palette = colorRampPalette(c(\"blue\", \"yellow\", \"red\")),  # Color gradient\n              cexplot = 1.5,                   # Point size\n              pch = 16,                        # Point shape (circle)\n              cex.lab = 1.5,                   # Axis label font size\n              cex.axis = 1.2,                  # Axis tick font size\n              cex.main = 1.5)                  # Title font size\n  \n  # Confidence band (shaded)\n  polygon(c(x_sorted, rev(x_sorted)),              # X coordinates\n          c(pred[, \"lwr\"], rev(pred[, \"upr\"])),    # Y coordinates\n          col = rgb(0.7, 0.7, 0.7, 0.4),            # Color and transparency\n          border = NA)                             # Remove border\n  \n  # Regression line\n  lines(x_sorted, pred[, \"fit\"], col = \"green\", lwd = 3)\n}\n\n# Plot using ggplot2 with facets\nlibrary(ggrain)\nalpha_plot &lt;- ggplot(alpha_combined, aes(x = diagnosis, y = Diversity, fill = diagnosis)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(0.9), outlier.shape = NA) +\n  theme_classic() +\n  facet_grid(Index ~ sequencing, scales = \"free_y\") +\n  labs(x = NULL,y = \"Alpha Diversity\") +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(color = \"black\", fill = NA, linewidth = 0.5),\n        strip.background = element_rect(color = \"black\", fill = \"gray90\")) +\n  # Annotate p-values in each facet\n  geom_text(\n    data = p_values, \n    aes(x = 1.5, y = Inf, label = paste0(\"p = \", formatC(p_value, format = \"f\", digits = 2))),\n    inherit.aes = FALSE, \n    vjust = 2, hjust = 0.5,size = 4\n  )\n\nalpha_plot &lt;- ggplot(alpha_combined, aes(x = diagnosis, y = Diversity, fill = diagnosis)) +\n  geom_rain(violin.args = list(alpha = 0.7),\n            point.args = list(size = 0.3, alpha = 1)) +\n  scale_fill_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n  scale_color_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n  theme_classic() +\n  facet_grid(Index ~ sequencing, scales = \"free_y\") +\n  labs(x = NULL, y = NULL) +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_rect(color = \"black\", fill = NA, linewidth = 1),\n    strip.background = element_blank(),     # Remove the grey boxes\n    # strip.background = element_rect(color = \"black\", fill = \"gray90\"),\n    # axis.text.y = element_blank(),     # Remove y-axis text\n    # axis.ticks.y = element_blank(),    # Remove y-axis ticks\n    axis.line = element_blank()\n  ) \nalpha_plot\n# Save the plot\nggsave(\"Real_Plots/Alpha_Diversity_combined.pdf\", alpha_plot, width = 5, height = 5)\n\n\n## Alpha Diversity Correlation----------------------------------------------------------------------------\nlibrary(energy)\nlibrary(XICOR)\nsample_names(phylo_16s) &lt;- gsub(\"-16s$\", \"\", sample_names(phylo_16s))\nphyseq.16s = rarefy_even_depth(phylo_16s,sample.size = 5000,rngseed = 2024)\nphyseq.wgs = rarefy_even_depth(phylo_wgs,sample.size = 30000,rngseed = 2024)\ncommon_samples &lt;- intersect(sample_names(physeq.16s), sample_names(physeq.wgs))\nphyseq.16s &lt;- prune_samples(common_samples, physeq.16s)\nphyseq.wgs &lt;- prune_samples(common_samples, physeq.wgs)\n\nAlp_ind_16s = alpha(physeq.16s,index = c(\"shannon\",\"inverse_simpson\",\"observed\"))\ncolnames(Alp_ind_16s) = c(\"observed\",\"shannon\",\"inverse_simpson\")\nAlp_ind_wgs = alpha(physeq.wgs,index = c(\"shannon\",\"inverse_simpson\",\"observed\"))\ncolnames(Alp_ind_wgs) = c(\"observed\",\"shannon\",\"inverse_simpson\")\nAlp_ind_wgs &lt;- Alp_ind_wgs[match(rownames(Alp_ind_16s), rownames(Alp_ind_wgs)), ]\nall(rownames(Alp_ind_16s) == rownames(Alp_ind_wgs)) ## make sure order is matched\n\n \n# Step 1: Combine and reshape data\nindex_list &lt;- c(\"observed\", \"shannon\", \"inverse_simpson\")\nlong_df &lt;- do.call(rbind, lapply(index_list, function(index) {\n  data.frame(\n    Index = index,\n    Alp_16s = Alp_ind_16s[[index]],\n    Alp_wgs = Alp_ind_wgs[[index]]\n  )\n}))\n\nlong_df_observed &lt;- long_df %&gt;% filter(Index==\"observed\")\nx = long_df_observed$Alp_16s\ny = long_df_observed$Alp_wgs\np &lt;- correlation_plot(x,y)\n\nplot_correlations_by_index &lt;- function(df, index_col = \"Index\", x_col = \"Alp_16s\", y_col = \"Alp_wgs\", outdir = \".\") {\n  unique_indices &lt;- unique(df[[index_col]])\n  \n  for (index in unique_indices) {\n    sub_df &lt;- df %&gt;% filter(.data[[index_col]] == index)\n    x &lt;- sub_df[[x_col]]\n    y &lt;- sub_df[[y_col]]\n    \n    # Create a safe filename\n    filename &lt;- file.path(outdir, paste0(\"correlation_plot_\", gsub(\"[^A-Za-z0-9]\", \"_\", index), \".pdf\"))\n    \n    # Save to PDF\n    pdf(filename, width = 10, height = 6)\n    correlation_plot(x, y)\n    # title(main = paste(\"Correlation Plot -\", index))\n    dev.off()\n  }\n}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\nplot_correlations_by_index &lt;- function(df, index_col = \"Index\", x_col = \"Alp_16s\", y_col = \"Alp_wgs\", outdir = \".\") {\n  unique_indices &lt;- unique(df[[index_col]])\n  \n  plot_list &lt;- list()\n  \n  for (index in unique_indices) {\n    sub_df &lt;- df %&gt;% filter(.data[[index_col]] == index)\n    x &lt;- sub_df[[x_col]]\n    y &lt;- sub_df[[y_col]]\n    \n    # Generate plot with title\n    p &lt;- correlation_plot(x, y)\n    \n    plot_list[[index]] &lt;- p\n  }\n  \n  # Combine plots vertically (ncol = 1)\n  combined_plot &lt;- wrap_plots(plot_list, ncol = 1)\n  \n  # Save combined plot\n  filename &lt;- file.path(outdir, \"alpha_correlation_plots_combined.pdf\")\n  ggsave(filename, plot = combined_plot, width = 10, height = 6 * length(plot_list))\n}\n\n\n\nplot_correlations_by_index(long_df)\n\ncorrelation_plot &lt;- function(x, y) {\n  par(bg=\"white\")\n  model &lt;- lm(y ~ x)\n  x_sorted &lt;- sort(x)\n  pred &lt;- predict(model, newdata = data.frame(x = x_sorted), interval = \"confidence\")\n  \n  # Diversity Correlation heatscatter\n  heatscatter(x, y,\n              xlab = \" \",                      # X label\n              ylab = \" \",                      # Y label\n              main = \" \",       # Main title\n              color.palette = colorRampPalette(c(\"blue\", \"yellow\", \"red\")),  # Color gradient\n              cexplot = 1.2,                   # Point size\n              pch = 16,                        # Point shape (circle)\n              cex.lab = 1.5,                   # Axis label font size\n              cex.axis = 2,                  # Axis tick font size\n              cex.main = 1.5)                  # Title font size\n  \n  \n  # Confidence band (shaded)\n  polygon(c(x_sorted, rev(x_sorted)),              # X coordinates\n          c(pred[, \"lwr\"], rev(pred[, \"upr\"])),    # Y coordinates\n          col = rgb(0.7, 0.7, 0.7, 0.4),            # Color and transparency\n          border = NA)                             # Remove border\n  \n  # Regression line\n  lines(x_sorted, pred[, \"fit\"], col = \"green\", lwd = 3)\n  box(lwd=1.5)\n}\n\n\n# Step 2: Plot with facet_wrap\nCombined_Plots = ggplot(long_df, aes(x = Alp_16s, y = Alp_wgs)) +\n  geom_point(size = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE,color = \"#0098B9\") +\n  facet_wrap(~Index, scales = \"free\", ncol = 1) +\n  theme_classic() +\n  labs(x = \"16S\", y = \"Shotgun\", title = NULL)\n\n\nggsave(\"Real_Plots/Alpha_Diversity_Cor_1.pdf\",Combined_Plots ,width = 3,height = 4)\n\n## Beta Diversity-16s -----------------------------------------------------------------------\nlibrary(vegan)\n\nphyseq = transform_sample_counts(phylo_16s, function(x) x / sum(x))\nmeta = meta(physeq)\n\nBeta_plots1 = lapply(c(\"bray\",\"unifrac\",\"wunifrac\"), function(metric){\n  permanova_result &lt;- adonis2(phyloseq::distance(physeq, method=metric) ~ diagnosis, \n                             data=data.frame(physeq@sam_data))\n  p_val &lt;- permanova_result$\"Pr(&gt;F)\"[1]\n  print(p_val)\n  ord = ordinate(physeq, method=\"PCoA\", distance = metric)\n  \n  eig_vals &lt;- ord$values$Relative_eig * 100\n  xlab &lt;- paste0(\"PCoA1 [\", round(eig_vals[1], 1), \"%]\")\n  ylab &lt;- paste0(\"PCoA2 [\", round(eig_vals[2], 1), \"%]\")\n  \n  ord_df &lt;- plot_ordination(physeq, ord, color = \"diagnosis\", justDF = TRUE)\n  \n  ggplot(ord_df, aes(x = Axis.1, y = Axis.2, color = diagnosis, fill = diagnosis)) +\n    geom_point(size = 0.5, alpha = 0.7) +  # control point size here\n    stat_ellipse(aes(group = diagnosis)) +\n    scale_fill_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n    scale_color_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n    theme_classic() +\n    labs(title = NULL,x = xlab, y = ylab) +\n    theme(\n      axis.ticks = element_blank(),\n      axis.text = element_blank(),\n      legend.position = \"none\"\n    )\n    # +annotate(\"text\", x = Inf, y = Inf, label = paste(\"p =\", round(p_val,2)), \n    #         hjust = 2, vjust = 1.1)\n    \n})\n## Beta Diversity-WGS -----------------------------------------------------------------------\nphyseq = transform_sample_counts(phylo_wgs, function(x) x / sum(x))\nmeta = meta(physeq)\n\nBeta_plots2 = lapply(c(\"bray\",\"unifrac\",\"wunifrac\"), function(metric){\n  permanova_result &lt;- adonis2(phyloseq::distance(physeq, method=metric) ~ diagnosis, \n                             data=data.frame(physeq@sam_data))\n  p_val &lt;- permanova_result$\"Pr(&gt;F)\"[1]\n  print(p_val)\n  ord = ordinate(physeq, method=\"PCoA\", distance = metric)\n  \n  eig_vals &lt;- ord$values$Relative_eig * 100\n  xlab &lt;- paste0(\"PCoA1 [\", round(eig_vals[1], 1), \"%]\")\n  ylab &lt;- paste0(\"PCoA2 [\", round(eig_vals[2], 1), \"%]\")\n  \n  ord_df &lt;- plot_ordination(physeq, ord, color = \"diagnosis\", justDF = TRUE)\n  \n  ggplot(ord_df, aes(x = Axis.1, y = Axis.2, color = diagnosis, fill = diagnosis)) +\n    geom_point(size = 0.5, alpha = 0.7) +  # control point size here\n    stat_ellipse(aes(group = diagnosis)) +\n    scale_fill_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n    scale_color_manual(values = c(\"uc\" = \"#7AC3DF\", \"cd\" = \"#EB7E60\")) +\n    theme_classic() +\n    labs(title = NULL,x = xlab, y = ylab) +\n    theme(\n      axis.ticks = element_blank(),\n      axis.text = element_blank(),\n      legend.position = \"none\"\n    )\n  # +annotate(\"text\", x = Inf, y = Inf, label = paste(\"p =\", round(p_val,2)), \n  #         hjust = 2, vjust = 1.1)\n})\n\nBeta_plots = wrap_plots(c(Beta_plots1, Beta_plots2),ncol = 3,legend.position = \"none\")\nggsave(\"Real_Plots/Beta_Diversity.pdf\",Beta_plots,width = 5,height = 3.5)"
  },
  {
    "objectID": "paper_code/Real_data.html#differential-analysis-and-results-visualization",
    "href": "paper_code/Real_data.html#differential-analysis-and-results-visualization",
    "title": "R code for real data analysis",
    "section": "3. Differential analysis and results visualization",
    "text": "3. Differential analysis and results visualization\n\n## Univariate Results -----------------------------------------------------------------------\nphyseq = physeq.16s.genus\ncolnames(physeq@tax_table) = c(\"Kingdom\", \"Phylum\", \"Class\",\"Order\", \"Family\", \"Genus\", \"Species\")\nDA_taxa = c(\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\")\ngroup = \"diagnosis\"\n\nlefse_results = run_lefse(physeq,group = group,norm = \"CPM\",kw_cutoff=1,wilcoxon_cutoff = 1,lda_cutoff=0,taxa_rank = \"Genus\")\naldex_results = run_aldex(physeq,group = group,p_adjust = \"BH\",pvalue_cutoff = 1)\nedger_results = run_edger(physeq,group = group,p_adjust = \"BH\",pvalue_cutoff = 1)\ndeseq2_results = run_deseq2(physeq,group = group,fitType = \"parametric\",sfType = \"poscounts\",p_adjust = \"BH\",pvalue_cutoff = 1)\nmetagenomeseq_results = run_metagenomeseq(physeq,group = group,p_adjust = \"BH\",pvalue_cutoff = 1,method = \"ZIG\")\nlimma_results = run_limma_voom(physeq,group = group,norm = \"none\",p_adjust = \"BH\",pvalue_cutoff =1)\nancombc_results = run_ancombc(physeq,group = group,p_adjust = \"BH\",pvalue_cutoff =1)\n\nout = list(lefse_results = lefse_results,aldex_results = aldex_results,\n           edger_results = edger_results,deseq2_results = deseq2_results,\n           metagenomeseq_results = metagenomeseq_results,\n           limma_results = limma_results,\n           ancombc_results = ancombc_results)\n\nsave(out,file = \"SixS_DA_results.Rdata\")\n\n\n## Visualization --------------------------------------------------------------------\nlibrary(reshape2)\nlibrary(dplyr)\nlibrary(tidyr)\nload(\"WGS_DA_results.Rdata\")\nDA_WGS = lefse_results\nload(\"SixS_DA_results.Rdata\")\nDA_16S = lefse_results\nrm(\"out\")\n\ndf_16S = as.data.frame(DA_16S@marker_table)           \ndf_16S$signed_lda &lt;- ifelse(df_16S$enrich_group == \"uc\", df_16S$ef_lda, -df_16S$ef_lda)\ndf_16S$significant &lt;- df_16S$pvalue &lt; 0.05 & df_16S$ef_lda&gt;=3\ndf_16S$platform = \"16S\"\nmatched_idx &lt;- match(df_16S$feature, rownames(ctax_table_c))\ndf_16S$feature[!is.na(matched_idx)] &lt;- ctax_table_c$genus[matched_idx[!is.na(matched_idx)]]\n\n  \ndf_WGS = as.data.frame(DA_WGS@marker_table)           \ndf_WGS$signed_lda &lt;- ifelse(df_WGS$enrich_group == \"uc\", df_WGS$ef_lda, -df_WGS$ef_lda)\ndf_WGS$significant &lt;- df_WGS$pvalue &lt; 0.05 & df_WGS$ef_lda &gt;= 3\ndf_WGS$platform = \"WGS\"\nmatched_idx &lt;- match(df_WGS$feature, rownames(ctax_table_c1))\ndf_WGS$feature[!is.na(matched_idx)] &lt;- ctax_table_c1$genus[matched_idx[!is.na(matched_idx)]]\n\n\nsig_16S &lt;- df_16S$feature[df_16S$significant]\nsig_16S &lt;- ctax_table_c$genus\nsig_WGS &lt;- df_WGS$feature[df_WGS$significant]\nsig_WGS &lt;- ctax_table_c1$genus\nall_common &lt;- intersect(sig_16S,sig_WGS)\n\n# Replace p__Firmicutes with p__Bacillota\ndf_WGS$feature &lt;- gsub(\"p__Firmicutes\", \"p__Bacillota\", df_WGS$feature)\n\n# Replace p__Proteobacteria with p__Pseudomonadota\ndf_WGS$feature &lt;- gsub(\"p__Proteobacteria\", \"p__Pseudomonadota\", df_WGS$feature)\n\n\ndf &lt;- rbind(df_16S, df_WGS) %&gt;%\n  filter(significant) %&gt;%\n  mutate(\n    group = case_when(\n      !(feature %in% all_common) & platform == \"16S\" ~ \"Unique-16S\",\n      !(feature %in% all_common) & platform == \"WGS\" ~ \"Unique-WGS\",\n      feature %in% all_common & feature %in% sig_16S & !(feature %in% sig_WGS) ~ \"Common-16S\",\n      feature %in% all_common & feature %in% sig_WGS & !(feature %in% sig_16S) ~ \"Common-WGS\",\n      feature %in% all_common & feature %in% sig_16S & feature %in% sig_WGS ~ \"Common-both\"\n    )\n  )\n\n\ndf$group &lt;- factor(df$group, levels = c(\"Unique-16S\", \"Common-16S\", \"Common-both\", \"Common-WGS\", \"Unique-WGS\"))\n\ndf &lt;- df %&gt;%\n  arrange(group, desc(signed_lda)) %&gt;%\n  mutate(feature = factor(feature, levels = rev(unique(feature))))\n\ndf$feature &lt;- gsub(\"\\\\|\", \";\", df$feature)\ndf$feature &lt;- gsub(\"k__Bacteria;\\\\|?\", \"\", df$feature)\n\nplot = ggplot(df, aes(x = signed_lda, y = feature, fill = platform)) +\n  geom_col(width = 0.6, position = position_dodge(width = 0.7)) +\n  geom_vline(xintercept = 0, color = \"gray40\", linetype = \"dashed\") +\n  scale_fill_manual(\n    values = c(\"16S\" = \"#ffa551\", \"WGS\" = \"#70afdf\")\n  ) +\n  xlim(-5,5)+\n  labs(x = NULL, y = NULL, fill = \"Platform\", title = NULL) +\n  theme_classic()+\n  theme(\n    axis.text.y = element_text(size = 15),\n    legend.position = \"none\",  # Top right inside plot\n    legend.justification = c(\"right\", \"top\"),\n    legend.background = element_rect(fill = \"white\", color = \"gray80\"),\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    plot.background = element_rect(fill = \"transparent\", color = NA)\n  )"
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "CoMPaSS",
    "section": "Installation",
    "text": "Installation\nYou can install CoMPaSS R package by:\n\n# Install devtools if you haven't already\ninstall.packages(\"devtools\")\nlibrary(devtools)\n\n# Install the package from GitHub\ninstall_github(\"bioscinema/concordance\")\n\n# Load your package\nlibrary(CoMPaSS)"
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "CoMPaSS",
    "section": "Quick Start",
    "text": "Quick Start\nThe following code is a quick example of simulating a microbiome dataset. The function SimulateMSeq() will take the estimate parameters, desired sample size, numbers of OTUs, etc. as input to generate simulation. The ComPaSS package ships with pre-configured simulation parameters so you can quickly generate example datasets. If you’d like to simulate using your own feature table, follow these steps below. Note: estimating parameters on very large OTU tables can be time-consuming.\n\n## First estimate parameters for our simulation (you can save the parameter as RData to do more simuation in the future)\npara &lt;- EstPara(myotu)  ##myotu is your otu table in data frame format\n\n## Simulate according to your estimated parameters\nN = 206 #sample size\ninput.conf &lt;- rnorm(N)\ninput.err &lt;- rnorm(N)\ninput.diff.otu.pct = NULL\ninput.diff.otu.mode = \"user_specified\"\nuser_specified_otu = common_genus[1:10]\ninput.covariate.eff.mean = 0.3\n\nnSim = 200\n\n## WGS simulation\nsim_WGS_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_WGS_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para, nSam = N, nOTU = nrow(myotu),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "CoMPaSS",
    "section": "Contact",
    "text": "Contact\nAny questions or suggestions on CoMPaSS are welcomed! Please report it on issues, contact Ruitao Liu (rxl761@case.edu) or Xi Qiao (xi.qiao@hci.utah.edu)."
  },
  {
    "objectID": "index.html#tutorial",
    "href": "index.html#tutorial",
    "title": "CoMPaSS",
    "section": "Tutorial",
    "text": "Tutorial\nFor the detailed tutorial, you can entered into tutorial from navigation bar. This section provide all the tutorial content summary.\n\nData simulation\nPower analysis and sample size calculation\nConcordance measurement for real data"
  },
  {
    "objectID": "paper_code/data_simulation.html",
    "href": "paper_code/data_simulation.html",
    "title": "Simulate microbiome dataset using user specified parameters",
    "section": "",
    "text": "library(CoMPASS)\n\n\nIntroduction\nIn this tutorial, we will demonstrate how to use CoMPASS to simulate data with user specified parameters if user do not want to do simulation based on predefined parameters in CoMPASS package. If user want to use predefined parameters to do simulation, user can go to the power analysis section.\n\n## First estimate parameters for our simulation (you can save the parameter as RData to do more simuation in the future)\npara &lt;- EstPara(myotu)  ##myotu is your otu table in data frame format\n\n## Simulate according to your estimated parameters\nN = 206 #sample size\ninput.conf &lt;- rnorm(N)\ninput.err &lt;- rnorm(N)\ninput.diff.otu.pct = NULL\ninput.diff.otu.mode = \"user_specified\"\nuser_specified_otu = common_genus[1:10]\ninput.covariate.eff.mean = 0.3\n\nnSim = 200\n\n## WGS simulation\nsim_WGS_Genus &lt;- replicate(nSim, list(), simplify = FALSE)\n\nfor (i in 1:nSim) {\n  sim_WGS_Genus[[i]] &lt;- SimulateMSeqU(\n    para = para, nSam = N, nOTU = nrow(myotu),\n    # True signal setting\n    diff.otu.pct = input.diff.otu.pct, diff.otu.direct = c(\"unbalanced\"), \n    diff.otu.mode = input.diff.otu.mode,\n    user_specified_otu = user_specified_otu ,\n    covariate.type = \"binary\", grp.ratio = 1,\n    covariate.eff.mean = input.covariate.eff.mean, covariate.eff.sd = 0,\n    # Confounder signal setting\n    confounder.type = \"none\", conf.cov.cor = 0.6,\n    conf.diff.otu.pct = 0, conf.nondiff.otu.pct = 0,\n    confounder.eff.mean = 0, confounder.eff.sd = 0,\n    # Depth setting\n    depth.mu = 10000, depth.theta = 5, depth.conf.factor = 0,\n    cont.conf = input.conf,epsilon = input.err)\n}"
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "CoMPaSS",
    "section": "Links",
    "text": "Links\n\nBrowse source code\nReport a bug"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "CoMPaSS",
    "section": "License",
    "text": "License\nMIT + file LICENSE"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "CoMPaSS",
    "section": "Citation",
    "text": "Citation\nSong D, Wang Q, Yan G et al. scDesign3 generates … Nat Biotechnol. 42, 247–252 (2024)."
  },
  {
    "objectID": "index.html#developers",
    "href": "index.html#developers",
    "title": "CoMPaSS",
    "section": "Developers",
    "text": "Developers\n\nRuitao Liu (maintainer)\n\nXi Qiao"
  },
  {
    "objectID": "paper_code/poweranalysis.html",
    "href": "paper_code/poweranalysis.html",
    "title": "Power analysis and sample size calculation",
    "section": "",
    "text": "# Load the package containing powerCalculation (adjust if needed)\nlibrary(concordance)\n\n\nPower Calculation\nThe powerCalculation() function in the CoMPASS R package offers three built-in simulation presets—gut, oral, and infant—and lets you specify your sequencing platform via the platform argument: \"amp\" for 16S rRNA amplicon data or \"wgs\" for whole-genome shotgun data.\n\n# Example: Evaluate power for gut data using amplicon sequencing (\"amp\")\n# with 50 simulation replicates, a significance level of 0.05,\n# 100 samples per simulation, and 200 OTUs simulated with 10% differential abundance.\nresult &lt;- powerCalculation(\n  data.type = \"gut\",     # Choose data type: \"gut\", \"oral\", or \"infant\"\n  method = \"amp\",        # Choose sequencing method: \"amp\" (16S) or \"wgs\" (WGS)\n  nSim = 50,             # Number of simulation replicates\n  alpha = 0.05,          # Significance level\n  nSam = 100,            # Number of samples per simulation replicate\n  nOTU = 200,            # Number of OTUs to simulate\n  diff.otu.pct = 0.1      # Proportion of OTUs that are differentially abundant\n  # All other parameters will use their default values.\n)\n\n# Print the overall estimated power (proportion of replicates with significant results)\nprint(result$overall_power)\n\n# Optionally, print the detection indicator for each replicate\nprint(result$replicate_power)\n\n\n\nSample Size Calculation\nThe sampleCalculationRange() function produces a line plot of statistical power across a user-specified range of sample sizes. You can control:\n\nlower_bound & upper_bound: the range of desired sample size\n\ntype: the data type (gut, oral, and infant)\n\nplatform: the sequencing platform (\"amp\" for 16S rRNA amplicon, \"wgs\" for shotgun)\n\nnOTU: the number of OTUs to include in the simulation\n\n\n# Evaluate power for sample sizes from 50 to 200 (in increments of 5)\n# for gut data using the 16S (amplicon) method.\nresult &lt;- sampleCalculationRange(\n  lower_bound = 50,\n  upper_bound = 200,\n  data.type = \"gut\",\n  method = \"amp\",\n  nSim = 100,       # Number of simulation replicates\n  nOTU = 300,       # Number of OTUs to simulate\n  diff.otu.pct = 0.1  # Proportion of OTUs that are differentially abundant\n)\n\n# Display the results:\nprint(result$data)\nprint(result$plot)\n\n\n\nPrice Calculation\nBudget considerations are critical: the priceCalculation() function estimates the total project cost across a user‐specified range of sample sizes to achieve a desired statistical power.\n\n# Minimal example call to priceCalculation:\nprice_estimates &lt;- priceCalculation(\n  target_power = 0.8,       # Desired power (80%)\n  lower_bound = 50,         # Minimum sample size to consider\n  upper_bound = 200,        # Maximum sample size to consider\n  data.type = \"gut\",        # Data type (\"gut\", \"oral\", or \"infant\")\n  nOTU=300\n)\n\n# Print the resulting data frame\nprint(price_estimates)"
  }
]